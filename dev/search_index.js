var documenterSearchIndex = {"docs":
[{"location":"design/#Build-your-own-AD","page":"Build your own AD","title":"Build your own AD","text":"","category":"section"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"The design of Yota is pretty simple, and the core of the package can be easily reproduced. In this section we discuss some of the key points in Yota implementation by creating a new AD system from scratch.","category":"page"},{"location":"design/#Theory","page":"Build your own AD","title":"Theory","text":"","category":"section"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Automatic differentiation is based on two things:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"set of \"primivitve\" functions such as +, sin, sqrt, etc. with known symbolic derivatives\nchain rule that describes how to combine them together to obtain the derivative of a complex function","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Reverse-mode AD works in two steps:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Forward pass, i.e. going from inputs to outputs and evaluating primitives in order.\nReverse pass, i.e. going from outputs to inputs and evaluating derivatives.","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"The reverse pass always starts with a \"seed\" - a derivative of the output variable w.r.t. itself (and thus equal to 1). This answer provides a complete step-by-step example of a (manual) reverse-mode differentiation for scalars.","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"While derivatives of scalar-valued functions w.r.t. scalar inputs are also scalars (i.e. have the same \"size\"), derivative of a vector-valued function f: Rⁿ → Rᵐ w.r.t. a vector input is called Jacobian and has size Rⁿ × Rᵐ. For large inputs and outputs it's a pretty huge matrix, so in practice it's never calculated as is. Instead, so-called vector-jacobian product (VJP) is used to propagate gradients to function inputs. For example:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"x = ...        # input\ny = f(x)       # both - x and y - are vectors\nz = g(y)       # output variabel, must be scalar\n\ndz/dz = 1               # seed\ndz/dy = vjp_g(dz/dz)\ndz/dx = vjp_f(dz/dy)","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Here vjp_f() essentially calculates dz/dy * J_f, but more efficiently.","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Sometimes forward and reverse pass share a piece of computation. In this case forward and backward pass can be combined into a single function, returning:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"primal value, i.e. output y of the function f(x)\npullback function that takes the gradient w.r.t. to the function output (dz/dy) and returns gradients w.r.t. its arguments (dz/dx)","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"See JAX docs for a mathematically robust explanation of VJP and pullbacks.","category":"page"},{"location":"design/#Practice","page":"Build your own AD","title":"Practice","text":"","category":"section"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Yota uses two packages under the hood:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Umlaut - code tracer that records execution as a list of primitive calls (Tape)\nChainRules - collection of VJP rules (rrule)","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"The idea is pretty simple. To differentiate a function call f(args...) we:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Recursively trace function execution to obtain a tape with only primitives.\nReplace all primitive calls y = g(xs...) with y, pb = rrule(g, xs....).\nAdd the seed to the tape.\nGo backwards, at each step invoking pullbacks to propagate function output gradient to its arguments, i.e. dxs = pb(dy).","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"We will use the following simple function as an example:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"g(a, b) = a * b\nh(a) = sin(a)\n\nf(x1, x2) = g(x1, x2) + h(x1)\nargs = (2.0, 3.0)","category":"page"},{"location":"design/#Trace-the-function","page":"Build your own AD","title":"Trace the function","text":"","category":"section"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"First of all, we need to let Umlaut know what functions to treat as primitives. By default, Umlaut records everything in Julia's built-in modules such as Base and Core, but we also want to record functions for which rrule is defined. To do so, we need to create a new tracing context and overload Umlaut.isprimitive method for it:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"using Umlaut\nusing ChainRules: rrule\n\nstruct GradCtx\n    pullbacks::Dict{Variable,Variable}    # ignore for now\n    derivs::Dict{Variable,Variable}       # ignore for now\nend\nGradCtx() = GradCtx(Dict(), Dict())\n\nfunction Umlaut.isprimitive(::GradCtx, f, args...)\n    Ts = [a isa DataType ? Type{a} : typeof(a) for a in (f, args...)]\n    # return type of rrule(f, args...) will be nothing only if there's no\n    # rrule for this function signature\n    if Core.Compiler.return_type(rrule, Ts) !== Nothing\n        return true\n    else\n        return false\n    end\nend","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Now we can check if the function call is traced correctly:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"val, tape = trace(f, args...; ctx=GradCtx())\n\n# output\n(6.909297426825682, Tape{GradCtx}\n  inp %1::typeof(f)\n  inp %2::Float64\n  inp %3::Float64\n  %4 = *(%2, %3)::Float64\n  %5 = sin(%2)::Float64\n  %6 = +(%4, %5)::Float64\n)","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Woohoo! Despite nested calls to h() and g(), Umlaut correctly recorded only primirives to the tape.","category":"page"},{"location":"design/#Replace-f(args...)-with-rrule(f,-args...)","page":"Build your own AD","title":"Replace f(args...) with rrule(f, args...)","text":"","category":"section"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Umlaut has a function replace!() that can do the replacement. But in this case we will calculate both f(args...) and rrule(f, args...), which is a double work. Instead we will do a slightly better thing and implement the replacement right during the tracing. To do so, we need to overload Umlaut.record_primitive!() as follows:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"const V = Umlaut.Variable\n\n\"\"\"\n    record_primitive!(tape::Tape{GradCtx}, v_fargs...)\n\nReplace ChainRules primitives `f(args...)` with a sequence:\n\n    rr = push!(tape, mkcall(rrule, f, args...))   # i.e. rrule(f, args...)\n    val = push!(tape, mkcall(getfield, rr, 1)     # extract value\n    pb = push!(tape, mkcall(getfield, rr, 2)      # extract pullback\n\"\"\"\nfunction Umlaut.record_primitive!(tape::Tape{GradCtx}, v_fargs...)\n    # v_xxx refer to instances of Umlaut.Variable or constants\n    # e.g. v_fargs = [+, V(1), 2.0]\n    v_f, v_args... = v_fargs\n    # fargs are actial values of a function and arguments\n    f, args... = [v isa V ? tape[v].val : v for v in v_fargs]\n    # record rrule(v_f, v_args...)\n    v_rr = push!(tape, mkcall(rrule, v_f, v_args...))\n    # get the output and the pullback as separate operations on the tape\n    v_val = push!(tape, mkcall(getfield, v_rr, 1))\n    v_pb = push!(tape, mkcall(getfield, v_rr, 2))\n    # store the mapping from the value var to pullback var\n    # in the tape's context\n    tape.c.pullbacks[v_val] = v_pb\n    # return value var, the same as if we recorded just f(args...)\n    return v_val\nend","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Just as the docstring explains it, for each primitive call f(args...) instead of recording it directly we record a sequence of three calls - one for rrule(f, args...) and two to destructure its result. We also save the mapping value -> pullback to the GradCtx.pullbacks field, which we prudently added to the context object.","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Let's see what we get now:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"val, tape = trace(f, args...; ctx=GradCtx())\n\n# output\n(6.909297426825682, Tape{GradCtx}\n  inp %1::typeof(f)\n  inp %2::Float64\n  inp %3::Float64\n  %4 = rrule(*, %2, %3)::Tuple{Float64, ChainRules.var\"#times_pullback2#1214\"{Float64, Float64}}\n  %5 = getfield(%4, 1)::Float64\n  %6 = getfield(%4, 2)::ChainRules.var\"#times_pullback2#1214\"{Float64, Float64}\n  %7 = rrule(sin, %2)::Tuple{Float64, ChainRules.var\"#sin_pullback#1175\"{Float64}}\n  %8 = getfield(%7, 1)::Float64\n  %9 = getfield(%7, 2)::ChainRules.var\"#sin_pullback#1175\"{Float64}\n  %10 = rrule(+, %5, %8)::Tuple{Float64, ChainRules.var\"#+_pullback#1203\"{Bool, Bool, ChainRulesCore.ProjectTo{Float64, NamedTuple{(), Tuple{}}}, ChainRulesCore.ProjectTo{Float64, NamedTuple{(), Tuple{}}}}}\n  %11 = getfield(%10, 1)::Float64\n  %12 = getfield(%10, 2)::ChainRules.var\"#+_pullback#1203\"{Bool, Bool, ChainRulesCore.ProjectTo{Float64, NamedTuple{(), Tuple{}}}, ChainRulesCore.ProjectTo{Float64, NamedTuple{(), Tuple{}}}}\n)","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"That's pretty verbose. Let's make it bit more readable:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Umlaut.show_format!(:compact)   # switch back with Umlaut.show_format!(:plain)\n\nprintln(tape)\n\n# output\nTape{GradCtx}\n  inp %1::typeof(f)\n  inp %2::Float64\n  inp %3::Float64\n  %5, %6 = [%4] = rrule(*, %2, %3)\n  %8, %9 = [%7] = rrule(sin, %2)\n  %11, %12 = [%10] = rrule(+, %5, %8)","category":"page"},{"location":"design/#Add-seed-to-the-tape","page":"Build your own AD","title":"Add seed to the tape","text":"","category":"section"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"As discussed earlier, seed is the derivative of the ouput variable w.r.t. itself, which is 1. We can record this constant to the tape as follows:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"dy = push!(tape, Constant(1))","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"We also hold mapping from a (primal) variable on the tape to its derivative variable in the GradCtx.derivs field. The very first pair we must add is from the tape result to the seed:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"tape.c.derivs[tape.result] = dy","category":"page"},{"location":"design/#Go-backwards,-propagate-derivatives","page":"Build your own AD","title":"Go backwards, propagate derivatives","text":"","category":"section"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"During the reverse pass we go backwards from the tape result variable (%11 in our case) to its inputs, at each step calling the pullback and updating the derivatives of a function arguments:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"# y is the output variable of the current Call operation\n# i.e. we assume call `y = fn(xs...)`\nfunction step_back!(tape::Tape, y::Variable)\n    # dy - output of the tape result w.r.t. y\n    dy = tape.c.derivs[y]\n    # extract pullback for y\n    pb = tape.c.pullbacks[y]\n    # record a call pb(dy)\n    dxs = push!(tape, mkcall(pb, dy))\n    # we don't actually need to go through call to `rrule` itself\n    # instead we propage derivs to original f(args...)\n    rr = tape[y].args[1]\n    y_fargs = tape[rr].args\n    # for each argument in f(args...) (including `f` itself)\n    for (i, x) in enumerate(y_fargs)\n        # if it's not a constant\n        if x isa V\n            # set the derivative var as getfield(xs, i)\n            dx = push!(tape, mkcall(getfield, dxs, i))\n            # WARNING: this is simplified version,\n            # won't work for multipath derivatives!\n            tape.c.derivs[bound(tape, x)] = bound(tape, dx)\n        end\n    end\nend","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Say, we are analyzing the last function call - %11, %12 = [%10] = rrule(+, %5, %8):","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"y points to %11\ndy points to our seed - %13\nthe pullback pb is stored in %12\nwe record dxs = pb(dy)\nand update derivatives for each argument in the original call +(%5, %8)","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Note that bold warning at the end: for illustrative purposes we set the mapping from the variable to its derivative, but in practice the same variable may influence the result in more than one way (e.g. x1 influences the result via both - g() and h()), and thus we need to set or add to the derivative. Let's fix it:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"import ChainRules: Tangent\n\n\ngetderiv(tape::Tape, v::Variable) = get(tape.c.derivs, bound(tape, v), nothing)\nsetderiv!(tape::Tape, x::Variable, dx::Variable) = (\n    tape.c.derivs[bound(tape, x)] = bound(tape, dx)\n)\nhasderiv(tape::Tape, v::Variable) = getderiv(tape, v) !== nothing\n\n\nfunction set_or_add_deriv!(tape::Tape, x::Variable, dx::Variable)\n    if !hasderiv(tape, x)\n        setderiv!(tape, x, dx)\n    else\n        old_dx = getderiv(tape, x)\n        if tape[dx].val isa Tangent || tape[old_dx].val isa Tangent\n            new_dx = push!(tape, mkcall(+, dx, old_dx))\n        else\n            new_dx = push!(tape, mkcall(broadcast, +, dx, old_dx))\n        end\n        setderiv!(tape, x, new_dx)\n    end\nend\n\n\nfunction step_back!(tape::Tape, y::Variable)\n    dy = tape.c.derivs[y]\n    pb = tape.c.pullbacks[y]\n    dxs = push!(tape, mkcall(pb, dy))\n    rr = tape[y].args[1]\n    y_fargs = tape[rr].args\n    for (i, x) in enumerate(y_fargs)\n        if x isa V\n            dx = push!(tape, mkcall(getfield, dxs, i))\n            # this line has changed\n            set_or_add_deriv!(tape, x, dx)\n        end\n    end\nend","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"The backward pass itself is simple:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"function back!(tape::Tape; seed=1)\n    # z - final variable (usually a loss)\n    # y - resulting variable of current op\n    # x - dependencies of y\n    # dy - derivative of z w.r.t. y\n    z = tape.result\n    # set seed and the first derivative\n    dy = push!(tape, Constant(seed))\n    tape.c.derivs[z] = dy\n    # the reverse pass, literally\n    for i=length(tape)-1:-1:1\n        y = bound(tape, V(i))\n        op = tape[y]\n        # note: skipping rrule() and pullbacks\n        if op isa Call && op.fn != rrule && !in(y, values(tape.c.pullbacks))\n            step_back!(tape, y)\n        end\n    end\nend\n\nback!(tape)\n\ntape.c.derivs\n\n# output\nDict{Variable, Variable} with 5 entries:\n  %8  => %16\n  %3  => %21\n  %2  => %20\n  %5  => %15\n  %11 => %13","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"tape.c.derivs now contains a map from all primal variables to their derivative variables. These include derivatives w.r.t. function inputs %2 and %3. For example:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"# bound variables for function inputs\n_, x1, x2 = inputs(tape)\n\n# derivaitves w.r.t. these inputs\ndx1 = tape.c.derivs[x1]\ndx2 = tape.c.derivs[x2]\n\n# values of these derivatives\ntape[dx1].val\ntape[dx2].val","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Finally, let's add a bit of post-processing and wrap it up into a single convenient function:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"import ChainRules: ZeroTangent, unthunk\n\n\nfunction grad(f, args...)\n    _, tape = trace(f, args...; ctx=GradCtx())\n    back!(tape)\n    # add a tuple of (val, (gradients...))\n    deriv_vars = [hasderiv(tape, v) ? getderiv(tape, v) : ZeroTangent() for v in inputs(tape)]\n    deriv_tuple = push!(tape, mkcall(tuple, deriv_vars...))\n    # unthunk results\n    deriv_tuple_unthunked = push!(tape, mkcall(map, unthunk, deriv_tuple))\n    new_result = push!(tape, mkcall(tuple, tape.result, deriv_tuple_unthunked))\n    # set result\n    tape.result = new_result\n    return tape[tape.result].val\nend\n\ngrad(f, 2.0, 3.0)   # (6.909297426825682, (ZeroTangent(), 2.5838531634528574, 2.0))\n\n# verify using numerical differentiation\nimport Yota.ngradient\n\nngradient(f, 2.0, 3.0)  # (2.583853163452614, 2.0000000000001696)","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"And we are done!","category":"page"},{"location":"design/#What's-not-covered","page":"Build your own AD","title":"What's not covered","text":"","category":"section"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"Although the code above is a valid AD system suitable for most functions, it doesn't cover many corner cases, including:","category":"page"},{"location":"design/","page":"Build your own AD","title":"Build your own AD","text":"functions with keyword arguments\nnon-differentiable paths\nobject constructors\nsome (often purposely) missing rrules\ncustom seeds\ntape caching, etc.","category":"page"},{"location":"cookbook/#Cookbook","page":"Cookbook","title":"Cookbook","text":"","category":"section"},{"location":"cookbook/","page":"Cookbook","title":"Cookbook","text":"Value and gradient:","category":"page"},{"location":"cookbook/","page":"Cookbook","title":"Cookbook","text":"using Yota      # hide\n\nf(x, y) = x^2 + sqrt(y)\nval, g = grad(f, 2.0, 3.0)\n_, dx, dy = g","category":"page"},{"location":"cookbook/","page":"Cookbook","title":"Cookbook","text":"Gradient tape (useful for further processing):","category":"page"},{"location":"cookbook/","page":"Cookbook","title":"Cookbook","text":"using Yota                # hide\nf(x, y) = x^2 + sqrt(y)   # hide\n\ntape = gradtape(f, 2.0, 3.0)","category":"page"},{"location":"cookbook/","page":"Cookbook","title":"Cookbook","text":"VJP, value and gradient:","category":"page"},{"location":"cookbook/","page":"Cookbook","title":"Cookbook","text":"using Yota                # hide\n\nh(w, b, x) = w * x .+ b\n\nw, b, x = rand(3, 4), rand(3), rand(4, 5)\nval, g = grad(h, w, b, x; seed=ones(3, 5))","category":"page"},{"location":"cookbook/","page":"Cookbook","title":"Cookbook","text":"VJP, value and pullback:","category":"page"},{"location":"cookbook/","page":"Cookbook","title":"Cookbook","text":"using Yota                # hide\nimport Yota: YotaRuleConfig, rrule_via_ad\n\nh(w, b, x) = w * x .+ b\n\nw, b, x = rand(3, 4), rand(3), rand(4, 5)\nval, pb = rrule_via_ad(YotaRuleConfig(), h, w, b, x)\npb(ones(3, 5))","category":"page"},{"location":"cookbook/","page":"Cookbook","title":"Cookbook","text":"Reset gradient cache:","category":"page"},{"location":"cookbook/","page":"Cookbook","title":"Cookbook","text":"import Yota    # hide\n\nYota.reset!()","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"CurrentModule = Yota","category":"page"},{"location":"reference/#Public-API","page":"Reference","title":"Public API","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"grad\nYota.gradtape\nYotaRuleConfig\nrrule_via_ad","category":"page"},{"location":"reference/#Yota.grad","page":"Reference","title":"Yota.grad","text":"grad(f, args...; seed=1)\n\nFind gradient of a callable f w.r.t. its arguments.\n\ngrad() returns two things: value of f(args...) and a tuple of grafients w.r.t. to its inputs (including the callable itself).\n\nusing Yota   # hide\n\nval, g = grad(x -> sum(x .+ 1), [1.0, 2.0, 3.0])\n\n# output\n(9.0, (ChainRulesCore.ZeroTangent(), [1.0, 1.0, 1.0]))\n\nBy default, grad() expects the callable to return a scalar. Vector-valued functions can be differentiated if a seed (starting value) is provided. Seed is equivalent to the vector in VJP notation.\n\nusing Yota   # hide\n\nval, g = grad(x -> 2x, [1.0, 2.0, 3.0]; seed=ones(3))\n\n# output\n([2.0, 4.0, 6.0], (ChainRulesCore.ZeroTangent(), [2.0, 2.0, 2.0]))\n\nAll gradients can be applied to original variables using update!() function.\n\nSee also: gradtape\n\n\n\n\n\n","category":"function"},{"location":"reference/#Yota.gradtape","page":"Reference","title":"Yota.gradtape","text":"gradtape(f::Union{Function, DataType}, args...; ctx=GradCtx(), seed=1)\ngradtape!(tape::Tape; seed=1)\n\nCalculate and record to the tape gradients of tape[tape.resultid] w.r.t. Input nodes. See grad() for more high-level API.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Yota.YotaRuleConfig","page":"Reference","title":"Yota.YotaRuleConfig","text":"YotaRuleConfig()\n\nChainRules.RuleConfig passed to all rrules in Yota. Extends RuleConfig{Union{NoForwardsMode,HasReverseMode}}.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ChainRulesCore.rrule_via_ad","page":"Reference","title":"ChainRulesCore.rrule_via_ad","text":"rrule_via_ad(::YotaRuleConfig, f, args...)\n\nGenerate rrule using Yota.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Internals","page":"Reference","title":"Internals","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"record_primitive!\nback!\nstep_back!\ntodo_list\ngrad_compile\nmake_rrule\n_getfield\nisstruct","category":"page"},{"location":"reference/#Yota.back!","page":"Reference","title":"Yota.back!","text":"Backpropagate through the tape, record derivatives as new operations.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Yota.step_back!","page":"Reference","title":"Yota.step_back!","text":"Make a single step of backpropagation.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Yota.todo_list","page":"Reference","title":"Yota.todo_list","text":"Collect variables that we need to step through during the reverse pass. The returned vector is already deduplicated and reverse-sorted\n\n\n\n\n\n","category":"function"},{"location":"reference/#Yota.grad_compile","page":"Reference","title":"Yota.grad_compile","text":"Like Umlaut.compile, but adds Yota specific ops\n\n\n\n\n\n","category":"function"},{"location":"reference/#Yota.make_rrule","page":"Reference","title":"Yota.make_rrule","text":"make_rrule(tape::Tape)\nmake_rrule(f, args...)\n\nGenerate a function equivalent to (but not extending) ChainRulesCore.rrule(), i.e. returning the primal value and the pullback.\n\nExamples:\n\nfoo(x) = 2x + 1\nrr = make_rrule(foo, 2.0)\nval, pb = rr(foo, 3.0)\npb(1.0)\n\n\n\n\n\n","category":"function"},{"location":"reference/#Yota._getfield","page":"Reference","title":"Yota._getfield","text":"_getfield(value, fld)\n\nThis function can be used instead of getfield() to bypass Yota rules during backpropagation.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Yota.isstruct","page":"Reference","title":"Yota.isstruct","text":"Check if an object is of a struct type, i.e. not a number or array\n\n\n\n\n\n","category":"function"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"#Yota","page":"Main","title":"Yota","text":"","category":"section"},{"location":"#Basic-usage","page":"Main","title":"Basic usage","text":"","category":"section"},{"location":"","page":"Main","title":"Main","text":"The most important function is grad(), which has the form grad(f, args...) -> (output, gradients), e.g.:","category":"page"},{"location":"","page":"Main","title":"Main","text":"using Yota\n\nf(x) = 5x + 3\n\nval, g = grad(f, 10)","category":"page"},{"location":"","page":"Main","title":"Main","text":"Here val is the result of f(10) and g is a tuple of gradients w.r.t. to the inputs including the function itself (which is ZeroTangent() in this case).","category":"page"},{"location":"","page":"Main","title":"Main","text":"A bit more complex example from the ML domain:","category":"page"},{"location":"","page":"Main","title":"Main","text":"using Yota\n\nmutable struct Linear{T}\n    W::AbstractArray{T,2}\n    b::AbstractArray{T}\nend\n\n(m::Linear)(X) = m.W * X .+ m.b\n\n# not very useful, but simple example of a loss function\nloss(m::Linear, X) = sum(m(X))\n\nm = Linear(rand(3,4), rand(3))\nX = rand(4,5)\n\nval, g = grad(loss, m, X)\n\n@show g[2].W\n@show g[2].b","category":"page"},{"location":"","page":"Main","title":"Main","text":"The computed gradients can then be used in the update!() function to modify tensors and fields of (mutable) structs:","category":"page"},{"location":"","page":"Main","title":"Main","text":"for i=1:100\n    val, g = grad(loss, m, X)\n    println(\"Loss value in $(i)th epoch: $val\")\n    update!(m, g[2], (x, gx) -> x .- 0.01gx)\nend","category":"page"}]
}
